{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jimitxdave/Jimit_INFO5731_Spring2026/blob/main/In_class_exercises_4_Text_Cleaning_(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d59ccffd",
      "metadata": {
        "id": "d59ccffd"
      },
      "source": [
        "# In-Class Assignment — Data Preprocessing & Cleaning (Text)  \n",
        "**Time:** 20 minutes  |  **Points:** 10  \n",
        "\n",
        "## Instructions\n",
        "- This is an individual in-class assignment.  \n",
        "- Write your code **inside each answer cell**.  \n",
        "- Print the required outputs.  \n",
        "- Submit your GitHub/Colab link as instructed by the instructor.\n",
        "\n",
        "\n",
        "You are given a small dataset of customer support messages as a **TAB-separated text file**:  \n",
        "- `support_messages.txt`\n",
        "\n",
        "You will download this file from **Canvas** and upload it to your **Google Colab** notebook.\n",
        "\n",
        "**How to upload it to your Google Colab notebook?**\n",
        "\n",
        "1. Download `support_messages.txt` from Canvas.\n",
        "3. In **the left sidebar**, click the **Files** icon (folder).  \n",
        "4. Click **Upload** and select `support_messages.txt`.\n",
        "\n",
        "6. RightAfter uploading, the file will appear in the Colab file list on the left.\n",
        "\n",
        "6. Right-click the file, copy its path, and paste it into the FILE_PATH variable in Q1.\n",
        "\n",
        "7. Run Q1 to load the dataset.\n",
        "\n",
        "\n",
        "\n",
        "> Important: Keep the file name exactly as `support_messages.txt`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b060c82",
      "metadata": {
        "id": "4b060c82"
      },
      "source": [
        "## Questions (Total = 10 points)\n",
        "\n",
        "### Q1 (1 point) — Load the dataset\n",
        "Load the TAB-separated file into a pandas DataFrame with columns: `id`, `message`.  \n",
        "Print: **(a)** `df.shape`, **(b)** `df.head(3)`.\n",
        "\n",
        "### Q2 (3 points) — Descriptive columns\n",
        "Add these columns for each message and print the full DataFrame:\n",
        "- `word_count`: number of words  \n",
        "- `char_count`: number of characters  \n",
        "- `num_count`: number of digits (0–9)  \n",
        "- `upper_word_count`: number of ALL-CAPS words (e.g., `\"WHY\"`, `\"DAMAGED\"`)  \n",
        "\n",
        "### Q3 (3 points) — Clean text\n",
        "Build a `clean_text(text)` function and create a new column `clean` with these steps **in order**:\n",
        "1) lowercase  \n",
        "2) remove punctuation/symbols (keep letters/numbers/spaces)  \n",
        "3) remove English stopwords (use **nltk** or **sklearn** list)  \n",
        "4) remove extra spaces  \n",
        "\n",
        "Print the **original** message and **clean** version for rows `id=1` and `id=4`.\n",
        "\n",
        "### Q4 (2 points) — Regex extraction\n",
        "Using RegEx, extract and create two new columns:\n",
        "- `order_id`: first occurrence of pattern `ORD-####` (case-insensitive; `ord-1060` is valid)  \n",
        "- `email`: first email address if present (otherwise `None`/`NaN`)  \n",
        "\n",
        "Print: `id`, `order_id`, `email` for all rows.\n",
        "\n",
        "### Q5 (1 point) — TF-IDF keywords\n",
        "Using the `clean` column, compute **TF-IDF** for the messages and print the **top 5 keywords** with the highest **average TF-IDF** across documents.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d5ab696",
      "metadata": {
        "id": "4d5ab696"
      },
      "outputs": [],
      "source": [
        "# Setup (run this cell first)\n",
        "import re\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "98307e5e",
      "metadata": {
        "id": "98307e5e"
      },
      "source": [
        "## Q1 (1 point) — Answer below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c4b8a8c",
      "metadata": {
        "id": "3c4b8a8c",
        "outputId": "e202dd2a-3b8e-46df-b76a-42997edb205c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(8, 2)\n",
            "   id                                            message\n",
            "0   1  Hi!! My ORDER is late :(  Order# ORD-1042. Ema...\n",
            "1   2  Refund please!!! I was charged 2 times... invo...\n",
            "2   3        Great service, thanks! arrived in 2 days :)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load TAB-separated file\n",
        "df = pd.read_csv(\"support_messages.txt\", sep=\"\\t\")\n",
        "\n",
        "# Print shape\n",
        "print(df.shape)\n",
        "\n",
        "# Print first 3 rows\n",
        "print(df.head(3))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "97eb3845",
      "metadata": {
        "id": "97eb3845"
      },
      "source": [
        "## Q2 (3 points) — Answer below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37d972dc",
      "metadata": {
        "id": "37d972dc",
        "outputId": "a2cde9e5-c09a-4012-f3f4-34c03f59c6ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   id                                            message  word_count  \\\n",
            "0   1  Hi!! My ORDER is late :(  Order# ORD-1042. Ema...          12   \n",
            "1   2  Refund please!!! I was charged 2 times... invo...          11   \n",
            "2   3        Great service, thanks! arrived in 2 days :)           8   \n",
            "3   4  WHY is my package DAMAGED??? tracking says del...           8   \n",
            "4   5  Need to change address: 7421 Frankford Rd Apt ...          12   \n",
            "5   6  Support ticket: ORD-1050. Call me at (469) 555...           9   \n",
            "6   7  I can’t login— password reset link not working...          10   \n",
            "7   8  Item missing from box. pls send replacement!! ...          10   \n",
            "\n",
            "   char_count  num_count  upper_word_count  \n",
            "0          73          4                 2  \n",
            "1          71          9                 2  \n",
            "2          43          1                 0  \n",
            "3          55          0                 2  \n",
            "4          67         13                 1  \n",
            "5          58         14                 2  \n",
            "6          76          0                 0  \n",
            "7          72          4                 0  \n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "# word_count\n",
        "df[\"word_count\"] = df[\"message\"].apply(lambda x: len(str(x).split()))\n",
        "\n",
        "# char_count\n",
        "df[\"char_count\"] = df[\"message\"].apply(len)\n",
        "\n",
        "# num_count (count digits)\n",
        "df[\"num_count\"] = df[\"message\"].apply(lambda x: len(re.findall(r\"\\d\", x)))\n",
        "\n",
        "# upper_word_count (ALL CAPS words)\n",
        "df[\"upper_word_count\"] = df[\"message\"].apply(\n",
        "    lambda x: len(re.findall(r\"\\b[A-Z]{2,}\\b\", x))\n",
        ")\n",
        "\n",
        "print(df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b289863b",
      "metadata": {
        "id": "b289863b"
      },
      "source": [
        "## Q3 (3 points) — Answer below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "479efbe4",
      "metadata": {
        "id": "479efbe4",
        "outputId": "f4d59747-e747-4cbd-b71a-9c99b507cfe6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                             message  \\\n",
            "0  Hi!! My ORDER is late :(  Order# ORD-1042. Ema...   \n",
            "3  WHY is my package DAMAGED??? tracking says del...   \n",
            "\n",
            "                                               clean  \n",
            "0  hi order late order ord1042 email saraaligmailcom  \n",
            "3            package damaged tracking says delivered  \n"
          ]
        }
      ],
      "source": [
        "import string\n",
        "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
        "\n",
        "def clean_text(text):\n",
        "    # 1. lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # 2. remove punctuation (keep letters/numbers/spaces)\n",
        "    text = re.sub(r\"[^a-z0-9\\s]\", \"\", text)\n",
        "\n",
        "    # 3. remove stopwords\n",
        "    words = text.split()\n",
        "    words = [w for w in words if w not in ENGLISH_STOP_WORDS]\n",
        "\n",
        "    # 4. remove extra spaces\n",
        "    text = \" \".join(words)\n",
        "\n",
        "    return text.strip()\n",
        "\n",
        "df[\"clean\"] = df[\"message\"].apply(clean_text)\n",
        "\n",
        "# Print rows id = 1 and id = 4\n",
        "print(df.loc[df[\"id\"].isin([1,4]), [\"message\", \"clean\"]])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40778881",
      "metadata": {
        "id": "40778881"
      },
      "source": [
        "## Q4 (2 points) — Answer below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9bcd6e3b",
      "metadata": {
        "id": "9bcd6e3b",
        "outputId": "e5da9a40-f3be-48a3-9014-c33ce5f2d9b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   id  order_id                  email\n",
            "0   1  ORD-1042     sara.Ali@gmail.com\n",
            "1   2  ORD-1042                    NaN\n",
            "2   3       NaN                    NaN\n",
            "3   4       NaN                    NaN\n",
            "4   5       NaN                    NaN\n",
            "5   6  ORD-1050                    NaN\n",
            "6   7       NaN  mehri.sattari@unt.edu\n",
            "7   8  ord-1060                    NaN\n"
          ]
        }
      ],
      "source": [
        "# Extract first order ID (case-insensitive)\n",
        "df[\"order_id\"] = df[\"message\"].str.extract(\n",
        "    r\"(ord-\\d+)\",\n",
        "    flags=re.IGNORECASE\n",
        ")\n",
        "\n",
        "# Extract first email\n",
        "df[\"email\"] = df[\"message\"].str.extract(\n",
        "    r\"([\\w\\.-]+@[\\w\\.-]+\\.\\w+)\"\n",
        ")\n",
        "\n",
        "print(df[[\"id\", \"order_id\", \"email\"]])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9417594",
      "metadata": {
        "id": "e9417594"
      },
      "source": [
        "## Q5 (1 point) — Answer below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77b7114b",
      "metadata": {
        "id": "77b7114b",
        "outputId": "4839bc6b-d81d-4ec9-bbf0-3bd2303307f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top 5 Keywords:\n",
            "order 0.1135\n",
            "ord1042 0.0829\n",
            "email 0.0795\n",
            "package 0.0559\n",
            "says 0.0559\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import numpy as np\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform(df[\"clean\"])\n",
        "\n",
        "# Average TF-IDF score across documents\n",
        "mean_tfidf = np.mean(X.toarray(), axis=0)\n",
        "\n",
        "# Get feature names\n",
        "features = vectorizer.get_feature_names_out()\n",
        "\n",
        "# Top 5 keywords\n",
        "top_indices = mean_tfidf.argsort()[-5:][::-1]\n",
        "top_keywords = [(features[i], mean_tfidf[i]) for i in top_indices]\n",
        "\n",
        "print(\"Top 5 Keywords:\")\n",
        "for word, score in top_keywords:\n",
        "    print(word, round(score, 4))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7f2c975",
      "metadata": {
        "id": "e7f2c975"
      },
      "source": [
        "## Grading Checklist\n",
        "- Q1: correct load + prints  \n",
        "- Q2: correct counts  \n",
        "- Q3: cleaning follows the required order + prints for id=1 and id=4  \n",
        "- Q4: regex extraction works (case-insensitive `ORD-####` and emails)  \n",
        "- Q5: prints 5 keywords + their scores (rounding is fine)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}